{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3d22e29-4fd4-4c72-b5c0-7801f1d082f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--config CONFIG]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\2077966\\AppData\\Roaming\\jupyter\\runtime\\kernel-182ae7cb-5663-474c-aeca-dfbca959288b.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2077966\\Anaconda3\\envs\\mlwine\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from src.get_data import read_params\n",
    "import argparse\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pprint import pprint\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def log_production_model(config_path):\n",
    "    config = read_params(config_path)\n",
    "\n",
    "\n",
    "    mlflow_config = config[\"mlflow_config\"] \n",
    "\n",
    "\n",
    "    model_name = mlflow_config[\"registered_model_name\"]\n",
    "\n",
    "\n",
    "    remote_server_uri = mlflow_config[\"remote_server_uri\"]\n",
    "\n",
    "    mlflow.set_tracking_uri(remote_server_uri)\n",
    "\n",
    "\n",
    "    runs = mlflow.search_runs(experiment_ids=[1])\n",
    "    lowest = runs[\"metrics.mae\"].sort_values(ascending=True)[0]\n",
    "    lowest_run_id = runs[runs[\"metrics.mae\"] == lowest][\"run_id\"][0]\n",
    "\n",
    "\n",
    "    client = MlflowClient()\n",
    "    for mv in client.search_model_versions(f\"name='{model_name}'\"):\n",
    "        mv = dict(mv)\n",
    "\n",
    "        if mv[\"run_id\"] == lowest_run_id:\n",
    "            current_version = mv[\"version\"]\n",
    "            logged_model = mv[\"source\"]\n",
    "            pprint(mv, indent=4)\n",
    "            client.transition_model_version_stage(\n",
    "                name=model_name,\n",
    "                version=current_version,\n",
    "                stage=\"Production\"\n",
    "            )\n",
    "        else:\n",
    "            current_version = mv[\"version\"]\n",
    "            client.transition_model_version_stage(\n",
    "                name=model_name,\n",
    "                version=current_version,\n",
    "                stage=\"Staging\"\n",
    "            )        \n",
    "\n",
    "\n",
    "    loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "    model_path = config[\"webapp_model_dir\"] #\"prediction_service/model\"\n",
    "\n",
    "    joblib.dump(loaded_model, model_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = argparse.ArgumentParser()\n",
    "    args.add_argument(\"--config\", default=\"params.yaml\")\n",
    "    parsed_args = args.parse_args()\n",
    "    data = log_production_model(config_path=parsed_args.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a17f23d-001d-49ee-9b7e-509f8b2b2dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\2077966\\\\OneDrive - Cognizant\\\\Desktop\\\\mlwine\\\\notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30092eec-347c-4a0c-9db8-d654d732fad8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'params.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27444\\1731758400.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;31m#     joblib.dump(loaded_model, model_path)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mlog_production_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"params.yaml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27444\\1731758400.py\u001b[0m in \u001b[0;36mlog_production_model\u001b[1;34m(config_path)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlog_production_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\2077966\\onedrive - cognizant\\desktop\\mlwine\\src\\get_data.py\u001b[0m in \u001b[0;36mread_params\u001b[1;34m(config_path)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0myaml_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msafe_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myaml_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'params.yaml'"
     ]
    }
   ],
   "source": [
    "from src.get_data import read_params\n",
    "import argparse\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pprint import pprint\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\2077966\\\\OneDrive - Cognizant\\\\Desktop\\\\mlwine\\\\notebooks')\n",
    "\n",
    "\n",
    "def log_production_model(config_path):\n",
    "    config = read_params(config_path)\n",
    "    \n",
    "    \n",
    "    mlflow_config = config[\"mlflow_config\"] \n",
    "    \n",
    "\n",
    "    model_name = mlflow_config[\"registered_model_name\"]\n",
    "\n",
    "\n",
    "    remote_server_uri = mlflow_config[\"remote_server_uri\"]\n",
    "\n",
    "    mlflow.set_tracking_uri(remote_server_uri)\n",
    "    \n",
    "    \n",
    "    runs = mlflow.search_runs(experiment_ids=1)\n",
    "    lowest = runs[\"metrics.mae\"].sort_values(ascending=True)[0]\n",
    "    lowest_run_id = runs[runs[\"metrics.mae\"] == lowest][\"run_id\"][0]\n",
    "    \n",
    "\n",
    "    client = MlflowClient()\n",
    "    for mv in client.search_model_versions(f\"name='{model_name}'\"):\n",
    "        mv = dict(mv)\n",
    "        pprint(mv, indent=4)\n",
    "        \n",
    "#         if mv[\"run_id\"] == lowest_run_id:\n",
    "#             current_version = mv[\"version\"]\n",
    "#             logged_model = mv[\"source\"]\n",
    "#             pprint(mv, indent=4)\n",
    "#             client.transition_model_version_stage(\n",
    "#                 name=model_name,\n",
    "#                 version=current_version,\n",
    "#                 stage=\"Production\"\n",
    "#             )\n",
    "#         else:\n",
    "#             current_version = mv[\"version\"]\n",
    "#             client.transition_model_version_stage(\n",
    "#                 name=model_name,\n",
    "#                 version=current_version,\n",
    "#                 stage=\"Staging\"\n",
    "#             )        \n",
    "\n",
    "\n",
    "#     loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "    \n",
    "#     model_path = config[\"webapp_model_dir\"] #\"prediction_service/model\"\n",
    "\n",
    "#     joblib.dump(loaded_model, model_path)\n",
    "\n",
    "log_production_model(\"params.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae0311-e2ac-4851-809e-b303279ea3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
